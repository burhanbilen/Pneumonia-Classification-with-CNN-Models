{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Burhan_Bilen_170205023.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vrzGJ_9jtsV"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.models import Sequential, Model, Input\n",
        "from keras.layers.core import Dense, Flatten, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmo7zCo4j2wc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz4zWJ4Qj4pP"
      },
      "source": [
        "train_path='./drive/MyDrive/Pneumonia/train/'\n",
        "test_path='./drive/MyDrive/Pneumonia/test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNizxKgbkVRD"
      },
      "source": [
        "batch = 64\n",
        "epochs_ = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRLJGO7bkXqr"
      },
      "source": [
        "def Data(shape_):    \n",
        "    train_normal = len(os.listdir(train_path+'NORMAL'))\n",
        "    train_bacterial = len(os.listdir(train_path+'BACTERIAL PNEUMONIA'))\n",
        "    train_viral = len(os.listdir(train_path+'VIRAL PNEUMONIA'))\n",
        "    \n",
        "    test_normal = len(os.listdir(test_path+'NORMAL'))\n",
        "    test_bacterial = len(os.listdir(test_path+'BACTERIAL PNEUMONIA'))\n",
        "    test_viral = len(os.listdir(test_path+'VIRAL PNEUMONIA'))\n",
        "    \n",
        "    train_data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.10)\n",
        "    test_data_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_data = train_data_generator.flow_from_directory(train_path, target_size=shape_, shuffle=False, color_mode=\"rgb\", class_mode=\"categorical\", batch_size = batch, subset=\"training\")\n",
        "    val_data = train_data_generator.flow_from_directory(train_path, target_size=shape_, shuffle=False, color_mode=\"rgb\", class_mode=\"categorical\", batch_size = batch, subset=\"validation\")\n",
        "    test_data = test_data_generator.flow_from_directory(test_path, target_size=shape_, shuffle=False, color_mode=\"rgb\", class_mode=\"categorical\", batch_size = 1)\n",
        "\n",
        "    return [train_data, val_data, test_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzOfpbphkf07"
      },
      "source": [
        "def Grafik(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])   \n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='lower right')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E44n1bfbkbt2"
      },
      "source": [
        "def KendiAlgoritmam():\n",
        "    dataset = Data((200,200))\n",
        "    train_data = dataset[0]\n",
        "    val_data = dataset[1]\n",
        "    test_data = dataset[2]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(96, kernel_size=(3,3), padding = \"same\", activation=\"relu\", input_shape=(200,200,3)))\n",
        "    model.add(Conv2D(96, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(128, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(128, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(256, kernel_size=(5,5), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(256, kernel_size=(5,5), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(128, kernel_size=(3,3), padding = \"valid\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation=\"relu\"))\n",
        "    model.add(Dense(512, activation=\"relu\"))\n",
        "    model.add(Dense(3, activation=\"softmax\"))\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    history = model.fit(train_data, steps_per_epoch=train_data.samples//batch, validation_data=val_data, epochs=epochs_, validation_steps=val_data.samples//batch)\n",
        "    \n",
        "    loss, accuracy = model.evaluate(test_data)\n",
        "    print(\"\\n\", loss, accuracy)\n",
        "    \n",
        "    y_true = test_data.classes\n",
        "    pred = model.predict_classes(test_data).astype(dtype = \"int32\")\n",
        "    \n",
        "    sns.heatmap(confusion_matrix(y_true, pred), annot= True)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\", classification_report(y_true, pred))\n",
        "    \n",
        "    Grafik(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PtxsOEqkpx8"
      },
      "source": [
        "def AlexNet(train, test):\n",
        "    dataset = Data((227,227))\n",
        "    train_data = dataset[0]\n",
        "    val_data = dataset[1]\n",
        "    test_data = dataset[2]\n",
        "    print(train_data)\n",
        "    \n",
        "    alexnet=Sequential()\n",
        "    alexnet.add(Conv2D(96,kernel_size=(11,11),strides=(4,4),activation='relu',input_shape=(227,227,3)))\n",
        "    alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "    alexnet.add(ZeroPadding2D((2,2)))\n",
        "    alexnet.add(Conv2D(256,kernel_size=(5,5),activation='relu',strides=(1,1)))\n",
        "    alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "    alexnet.add(ZeroPadding2D((1,1)))\n",
        "    alexnet.add(Conv2D(384,kernel_size=(3,3),activation='relu',strides=(1,1)))\n",
        "    alexnet.add(ZeroPadding2D((1,1)))\n",
        "    alexnet.add(Conv2D(384,kernel_size=(3,3),activation='relu',strides=(1,1)))\n",
        "    alexnet.add(ZeroPadding2D((1,1)))\n",
        "    alexnet.add(Conv2D(256,kernel_size=(3,3),activation='relu',strides=(1,1)))\n",
        "    alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "    alexnet.add(Flatten())\n",
        "    alexnet.add(Dense(4096,activation='relu'))\n",
        "    alexnet.add(Dense(4096,activation='relu'))\n",
        "    alexnet.add(Dense(196,activation='softmax'))\n",
        "    alexnet.summary()\n",
        "\n",
        "    alexnet.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    \n",
        "    history=alexnet.fit(train_data, steps_per_epoch=train_data.samples//32, validation_data=val_data, epochs=epochs_, validation_steps=val_data.samples//32)\n",
        "    \n",
        "    loss, accuracy = alexnet.evaluate(test_data)\n",
        "    print(\"\\n\", loss, accuracy)\n",
        "    \n",
        "    y_true = test_data.classes\n",
        "    pred = alexnet.predict_classes(test_data).astype(dtype = \"int32\")\n",
        "    \n",
        "    sns.heatmap(confusion_matrix(y_true, pred), annot= True)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\", classification_report(y_true, pred))\n",
        "    \n",
        "    Grafik(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiCfH8AgktTr"
      },
      "source": [
        "def VGG16(train, test):\n",
        "    dataset = Data((224,224))\n",
        "    train_data = dataset[0]\n",
        "    val_data = dataset[1]\n",
        "    test_data = dataset[2]\n",
        "    \n",
        "    input_ = Input(shape=(224,224,3))\n",
        "    vgg16 = Conv2D(64, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(input_)\n",
        "    vgg16 = Conv2D(64, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = MaxPooling2D(pool_size=(2,2))(vgg16)\n",
        "    vgg16 = Conv2D(128, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(128, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = MaxPooling2D(pool_size=(2,2))(vgg16)\n",
        "    vgg16 = Conv2D(256, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(256, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(256, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(256, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = MaxPooling2D(pool_size=(2,2))(vgg16)\n",
        "    vgg16 = Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = MaxPooling2D(pool_size=(2,2))(vgg16)\n",
        "    vgg16 = Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = Conv2D(512, kernel_size=(3,3), padding = \"same\", activation=\"relu\")(vgg16)\n",
        "    vgg16 = MaxPooling2D(pool_size=(2,2))(vgg16)\n",
        "    vgg16 = Flatten()(vgg16)\n",
        "    vgg16 = Dense(1024, activation=\"relu\")(vgg16)\n",
        "    vgg16 = Dense(512, activation=\"relu\")(vgg16)\n",
        "    output_ = Dense(2, activation=\"softmax\")\n",
        "    \n",
        "    vgg16_model=Model(inputs=input_, outputs=output_)\n",
        "\n",
        "    vgg16_model.summary()\n",
        "    \n",
        "    vgg16_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    history = vgg16_model.fit(train_data, steps_per_epoch=train_data.samples//batch, validation_data=val_data, epochs=epochs_, validation_steps=val_data.samples//batch)\n",
        "    \n",
        "    loss, accuracy = vgg16_model.evaluate(test_data)\n",
        "    print(\"\\n\", loss, accuracy)\n",
        "    \n",
        "    y_true = test_data.classes\n",
        "    pred = vgg16_model.predict_classes(test_data).astype(dtype = \"int32\")\n",
        "    \n",
        "    sns.heatmap(confusion_matrix(y_true, pred), annot= True)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\", classification_report(y_true, pred))\n",
        "    \n",
        "    Grafik(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UNGM3GKkwQT"
      },
      "source": [
        "def Inception(train, test):\n",
        "    dataset = Data((299,299))\n",
        "    train_data = dataset[0]\n",
        "    val_data = dataset[1]\n",
        "    test_data = dataset[2]\n",
        "    \n",
        "    transfer_inception=InceptionV3(weights=\"imagenet\", input_shape=(299,299,3),include_top=False) #weights='imagenet'\n",
        "    transfer_inception.trainable=False\n",
        "    \n",
        "    flat=Flatten()(transfer_inception.output)\n",
        "    dense=Dense(512,activation='relu')(flat)\n",
        "    out=Dense(3,activation='softmax')(dense)\n",
        "    model=Model(inputs=transfer_inception.inputs,outputs=out)\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    \n",
        "    history = model.fit(train_data, steps_per_epoch=train_data.samples//batch, validation_data=val_data, epochs=epochs_, validation_steps=val_data.samples//batch)\n",
        "    \n",
        "    loss, accuracy = model.evaluate(test_data)\n",
        "    print(\"\\n\", loss, accuracy)\n",
        "    \n",
        "    y_true = test_data.classes\n",
        "    pred = model.predict_classes(test_data).astype(dtype = \"int32\")\n",
        "    \n",
        "    sns.heatmap(confusion_matrix(y_true, pred), annot= True)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\", classification_report(y_true, pred))\n",
        "    \n",
        "    Grafik(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4px0Bk6kzCn"
      },
      "source": [
        "KendiAlgoritmam()\n",
        "#AlexNet()\n",
        "#VGG16()\n",
        "#InceptionV3()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}