{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Burhan_Bilen_170205023 (3).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vrzGJ_9jtsV"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.models import Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten,GlobalAveragePooling2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmo7zCo4j2wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b7c920-8279-4ca1-c2c5-eef595640d62"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz4zWJ4Qj4pP"
      },
      "source": [
        "train_path='./drive/MyDrive/Pneumonia/train/'\n",
        "test_path='./drive/MyDrive/Pneumonia/test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNizxKgbkVRD"
      },
      "source": [
        "batch = 64\n",
        "epochs_ = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRLJGO7bkXqr"
      },
      "source": [
        "def Data(shape_):    \n",
        "    train_normal = len(os.listdir(train_path+'NORMAL'))\n",
        "    train_bacterial = len(os.listdir(train_path+'BACTERIAL PNEUMONIA'))\n",
        "    train_viral = len(os.listdir(train_path+'VIRAL PNEUMONIA'))\n",
        "    \n",
        "    test_normal = len(os.listdir(test_path+'NORMAL'))\n",
        "    test_bacterial = len(os.listdir(test_path+'BACTERIAL PNEUMONIA'))\n",
        "    test_viral = len(os.listdir(test_path+'VIRAL PNEUMONIA'))\n",
        "\n",
        "    train = [train_normal,train_bacterial,train_viral]\n",
        "    test = [test_normal,test_bacterial,test_viral]\n",
        "\n",
        "    df = pd.DataFrame(list(zip(train, test)), index =['Normal', 'Bakteriyel', 'Viral'], columns=['Train', 'Test'])\n",
        "    print(df)\n",
        "    df.plot(kind='bar')\n",
        "    plt.show()\n",
        "    \n",
        "    train_data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.10)\n",
        "    test_data_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_data = train_data_generator.flow_from_directory(train_path, target_size=shape_, class_mode=\"categorical\", batch_size = batch, subset=\"training\")\n",
        "    val_data = train_data_generator.flow_from_directory(train_path, target_size=shape_, class_mode=\"categorical\", batch_size = batch, subset=\"validation\")\n",
        "    test_data = test_data_generator.flow_from_directory(test_path, target_size=shape_, shuffle=False, class_mode=\"categorical\", batch_size = 1)\n",
        "\n",
        "    return [train_data, val_data, test_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzOfpbphkf07"
      },
      "source": [
        "def Graphics(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])   \n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='lower right')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E44n1bfbkbt2"
      },
      "source": [
        "def simpleCNN():\n",
        "    dataset = Data((230,230))\n",
        "    train_data = dataset[0]\n",
        "    val_data = dataset[1]\n",
        "    test_data = dataset[2]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=(2,2), padding = \"same\", activation=\"relu\", input_shape=(230,230,3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(96, kernel_size=(2,2), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(128, kernel_size=(2,2), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(256, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(256, kernel_size=(2,2), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(256, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(256, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(128, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(96, kernel_size=(3,3), padding = \"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(96, activation=\"relu\"))\n",
        "    model.add(Dense(3, activation=\"softmax\"))\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    history = model.fit(train_data, steps_per_epoch=train_data.samples//batch, validation_data=val_data, epochs=epochs_, validation_steps=val_data.samples//batch)\n",
        "    \n",
        "    loss, accuracy = model.evaluate(test_data)\n",
        "    print(\"\\n\", loss, accuracy)\n",
        "    \n",
        "    y_true = test_data.classes\n",
        "\n",
        "    pred = model.predict_classes(test_data).astype(dtype = \"int32\")\n",
        "    \n",
        "    sns.heatmap(confusion_matrix(y_true, pred), annot= True, fmt='g')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\", classification_report(y_true, pred))\n",
        "    \n",
        "    Graphics(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PtxsOEqkpx8"
      },
      "source": [
        "def AlexNet():\n",
        "    dataset = Data((227,227))\n",
        "    train_data = dataset[0]\n",
        "    val_data = dataset[1]\n",
        "    test_data = dataset[2]\n",
        "    \n",
        "    alexnet=Sequential()\n",
        "    alexnet.add(Conv2D(96,kernel_size=(11,11),strides=(4,4),activation='relu',input_shape=(227,227,3)))\n",
        "    alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "    alexnet.add(ZeroPadding2D((2,2)))\n",
        "    alexnet.add(Conv2D(256,kernel_size=(5,5),activation='relu',strides=(1,1)))\n",
        "    alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "    alexnet.add(ZeroPadding2D((1,1)))\n",
        "    alexnet.add(Conv2D(384,kernel_size=(3,3),activation='relu',strides=(1,1)))\n",
        "    alexnet.add(ZeroPadding2D((1,1)))\n",
        "    alexnet.add(Conv2D(384,kernel_size=(3,3),activation='relu',strides=(1,1)))\n",
        "    alexnet.add(ZeroPadding2D((1,1)))\n",
        "    alexnet.add(Conv2D(256,kernel_size=(3,3),activation='relu',strides=(1,1)))\n",
        "    alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "    alexnet.add(Flatten())\n",
        "    alexnet.add(Dense(4096,activation='relu'))\n",
        "    alexnet.add(Dense(4096,activation='relu'))\n",
        "    alexnet.add(Dense(3,activation='softmax'))\n",
        "    alexnet.summary()\n",
        "\n",
        "    alexnet.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    \n",
        "    history=alexnet.fit(train_data, steps_per_epoch=train_data.samples//batch, validation_data=val_data, epochs=epochs_, validation_steps=val_data.samples//batch)\n",
        "    \n",
        "    loss, accuracy = alexnet.evaluate(test_data)\n",
        "    print(\"\\n\", loss, accuracy)\n",
        "    \n",
        "    y_true = test_data.classes\n",
        "    pred = alexnet.predict_classes(test_data).astype(dtype = \"int32\")\n",
        "    \n",
        "    sns.heatmap(confusion_matrix(y_true, pred), annot= True, fmt='g')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\", classification_report(y_true, pred))\n",
        "    \n",
        "    Graphics(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiCfH8AgktTr"
      },
      "source": [
        "def vgg_16():\n",
        "    dataset = Data((224,224))\n",
        "    train_data = dataset[0]\n",
        "    val_data = dataset[1]\n",
        "    test_data = dataset[2]\n",
        "\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(64, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(128, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(128, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(256, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(256, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(256, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(512, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(512, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(512, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(512, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(512, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(512, kernel_size=(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096,activation='relu'))\n",
        "    model.add(Dense(4096,activation='relu'))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    history = model.fit(train_data, steps_per_epoch=train_data.samples//batch, validation_data=val_data, epochs=epochs_, validation_steps=val_data.samples//batch)\n",
        "    \n",
        "    loss, accuracy = model.evaluate(test_data)\n",
        "    print(\"\\n\", loss, accuracy)\n",
        "    \n",
        "    y_true = test_data.classes\n",
        "    \n",
        "    pred = model.predict(test_data)\n",
        "    classes = np.argmax(pred, axis=-1)\n",
        "    \n",
        "    sns.heatmap(confusion_matrix(y_true, classes), annot= True, fmt='g')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\", classification_report(y_true, classes))\n",
        "    \n",
        "    Graphics(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UNGM3GKkwQT"
      },
      "source": [
        "def resnet50():\n",
        "    dataset = Data((224,224))\n",
        "    train_data = dataset[0]\n",
        "    val_data = dataset[1]\n",
        "    test_data = dataset[2]\n",
        "\n",
        "    import tensorflow as tf\n",
        "    resnet = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    for layer in resnet.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = resnet.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "    output = Dense(units=3, activation='softmax')(x)\n",
        "\n",
        "    model = Model(resnet.inputs, output)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "    history = model.fit(train_data, steps_per_epoch=train_data.samples//batch, validation_data=val_data, epochs=epochs_, validation_steps=val_data.samples//batch)\n",
        "\n",
        "    loss, accuracy = model.evaluate(test_data)\n",
        "    print(\"\\n\", loss, accuracy)\n",
        "\n",
        "    y_true = test_data.classes\n",
        "    pred = model.predict(test_data)\n",
        "\n",
        "    classes = np.argmax(pred,axis=1)\n",
        "\n",
        "    sns.heatmap(confusion_matrix(y_true, classes), annot= True, fmt='g')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\", classification_report(y_true, classes))\n",
        "\n",
        "    Graphics(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4px0Bk6kzCn"
      },
      "source": [
        "simpleCNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP0jE_nZy0Go"
      },
      "source": [
        "AlexNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgQk8S1X-ECP"
      },
      "source": [
        "vgg_16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQVLS-1CC6vl"
      },
      "source": [
        "resnet50()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}